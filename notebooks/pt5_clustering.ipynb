{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26294103",
   "metadata": {},
   "source": [
    "# HDBSCAN Geospatial Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02642163",
   "metadata": {},
   "source": [
    "## Loading Libraries & Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6f9bd4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import hdbscan\n",
    "from hdbscan import approximate_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7622c31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading CSV\n",
    "listings = pd.read_csv(r\"..\\data\\listings_cleaner.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a851862",
   "metadata": {},
   "source": [
    "## Preprocessing for Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a66240a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering listings above $1800 (Massive price outliers)\n",
    "listings = listings[listings[\"price\"] <= 1800]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf5fb768",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pasting drops and renames\n",
    "listings = listings.drop(columns = \n",
    "                [\"Unnamed: 0.1\", \"Unnamed: 0\", \"host_id\", \"id\", # Removing index columns and IDs\n",
    "                \"name\", \"last_scrape_period\", \"description\", \"last_scraped\"]) # Removing free text columns\n",
    "\n",
    "# Renaming long column names to make them easier to work with\n",
    "listings = listings.rename(columns = {\n",
    "    \"accommodates\": \"accomm\", \"instant_bookable\": \"instant_book\",\n",
    "    \"neighbourhood_group_cleansed\": \"boro\", \"host_neighbourhood\": \"nbhd\",\n",
    "    \"host_has_profile_pic\": \"has_pfp\", \"host_tenure\": \"tenure\", \"host_is_superhost\": \"is_superhost\",\n",
    "    \"host_identity_verified\": \"id_ver\", \"host_listings_count\": \"lst_cnt\", \"host_total_listings_count\": \"total_lst_cnt\",\n",
    "    \"host_response_rate\": \"rsp_rate\", \"host_response_time\": \"rsp_time\", \"host_acceptance_rate\": \"accept_rate\",\n",
    "    \"availability_30\": \"avail_30\", \"availability_365\": \"avail_365\", \"has_availability\": \"has_avail\",\n",
    "    \"maximum_nights\": \"max_nights\", \"minimum_nights\": \"min_nights\",\n",
    "    \"number_of_reviews\": \"no_rev\", \"review_scores_accuracy\": \"rev_acc\", \"review_scores_checkin\": \"rev_checkin\",\n",
    "    \"review_scores_cleanliness\": \"rev_clean\", \"review_scores_communication\": \"rev_coms\", \"review_scores_location\": \"rev_loc\",\n",
    "    \"review_scores_value\": \"rev_val\", \"review_scores_rating\": \"rev_rating\",\n",
    "    \"scrape_2024-10\": \"oct\", \"scrape_2024-11\": \"nov\", \"scrape_2024-12\": \"dec\", \"scrape_2025-01\": \"jan\",\n",
    "    \"scrape_2025-02\": \"feb\", \"scrape_2025-03\": \"mar\", \"scrape_2025-04\": \"apr\", \"scrape_2025-05\": \"may\", \n",
    "    \"scrape_2025-06\": \"june\", \"scrape_2025-07\": \"jul\", \"scrape_2025-08\": \"aug\", \n",
    "    \"prop_apartment\": \"prop_apt\", \"prop_entire home/apt\": \"prop_entire_home_apt\",\"prop_hotel room\": \"prop_hotel_room\",\n",
    "    \"prop_private room\": \"prop_private_room\", \"prop_shared room\": \"prop_shared_room\",\n",
    "    \"latitude\": \"lat\", \"longitude\": \"lon\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53955cf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Brooklyn', 'Manhattan', 'Queens', 'Bronx', 'Staten Island'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Viewing exact borough names\n",
    "listings[\"boro\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3fa0cb",
   "metadata": {},
   "source": [
    "## Queens Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b0d4609",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subsetting to only Queens\n",
    "qns_df = listings[listings[\"boro\"] == \"Queens\"].copy()\n",
    "\n",
    "# Train-Test Splits by index\n",
    "qns_train_idx, qns_test_idx = train_test_split(qns_df.index, train_size = 0.8, random_state = 2025)\n",
    "qns_train = qns_df.loc[qns_train_idx].copy()\n",
    "qns_test  = qns_df.loc[qns_test_idx].copy()\n",
    "\n",
    "# Getting Lat/Lon as NumPy Arrays\n",
    "X_train = qns_train[['lat', 'lon']].values\n",
    "X_test  = qns_test[['lat', 'lon']].values\n",
    "\n",
    "# Scaling Lat/Lon coordinates\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled  = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40b4f2ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131\n",
      "38173\n",
      "15.672870451344837\n"
     ]
    }
   ],
   "source": [
    "# Getting unique neighborhoods\n",
    "print(qns_df[\"nbhd\"].nunique()) # 131 unique neighborhoods in Queens\n",
    "print(len(qns_df)) # 38173 unique listings in Queens\n",
    "print((len(qns_df) / len(listings)) * 100) # 15.67% of listings are in Queens\n",
    "\n",
    "qns_cluster_size = 16 # Setting to 16 clusters for about the percentage of listings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b31546b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\adria\\anaconda3\\envs\\analytics\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\adria\\anaconda3\\envs\\analytics\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Fitting HDBSCAN\n",
    "cluster = hdbscan.HDBSCAN(min_cluster_size = qns_cluster_size, \n",
    "                        metric = \"euclidean\",  # Euclidean metric best for Queens - too small of a geo for haversine. Not grid-like for manhattan.\n",
    "                        prediction_data = True, \n",
    "                        cluster_selection_epsilon = 0.05)\n",
    "\n",
    "cluster_labels_train = cluster.fit_predict(X_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3a448f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigning cluster labels to training data\n",
    "qns_train[\"cluster\"] = cluster_labels_train\n",
    "\n",
    "# Assigning cluster labels to test data with approximate predictions\n",
    "cluster_labels_test, _ = hdbscan.approximate_predict(cluster, X_test_scaled)\n",
    "qns_test['cluster'] = cluster_labels_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a630e3",
   "metadata": {},
   "source": [
    "## Brooklyn Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1391b77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subsetting to only Brooklyn\n",
    "bk_df = listings[listings[\"boro\"] == \"Brooklyn\"].copy()\n",
    "\n",
    "# Train-Test Splits by index\n",
    "bk_train_idx, bk_test_idx = train_test_split(bk_df.index, train_size = 0.8, random_state = 2025)\n",
    "bk_train = bk_df.loc[bk_train_idx].copy()\n",
    "bk_test  = bk_df.loc[bk_test_idx].copy()\n",
    "\n",
    "# Getting Lat/Lon as NumPy Arrays\n",
    "X_train = bk_train[['lat', 'lon']].values\n",
    "X_test  = bk_test[['lat', 'lon']].values\n",
    "\n",
    "# Scaling Lat/Lon coordinates\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled  = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84e54aef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "212\n",
      "84393\n",
      "34.649636025472056\n"
     ]
    }
   ],
   "source": [
    "# Getting unique neighborhoods\n",
    "print(bk_df[\"nbhd\"].nunique()) # 212 unique neighborhoods in Brooklyn\n",
    "print(len(bk_df)) # 84393 unique listings in Brooklyn\n",
    "print((len(bk_df) / len(listings)) * 100) # 34.65% of listings are in Brooklyn\n",
    "\n",
    "bk_cluster_size = 35 # Setting the number of clusters to the percentage of listings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e0efc812",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\adria\\anaconda3\\envs\\analytics\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\adria\\anaconda3\\envs\\analytics\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Fitting HDBSCAN\n",
    "cluster = hdbscan.HDBSCAN(min_cluster_size = bk_cluster_size, \n",
    "                        metric = \"euclidean\",  # Euclidean metric best for Brooklyn - too small of a geo for haversine. Not grid-like for manhattan.\n",
    "                        prediction_data = True, \n",
    "                        cluster_selection_epsilon = 0.05) \n",
    "\n",
    "cluster_labels_train = cluster.fit_predict(X_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e6b484e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigning cluster labels to training data\n",
    "bk_train[\"cluster\"] = cluster_labels_train\n",
    "\n",
    "# Assigning cluster labels to test data with approximate predictions\n",
    "cluster_labels_test, _ = hdbscan.approximate_predict(cluster, X_test_scaled)\n",
    "bk_test[\"cluster\"] = cluster_labels_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f9fa5d",
   "metadata": {},
   "source": [
    "## The Bronx Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "78bf3f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subsetting to only The Bronx\n",
    "bx_df = listings[listings[\"boro\"] == \"Bronx\"].copy()\n",
    "\n",
    "# Train-Test Splits by index\n",
    "bx_train_idx, bx_test_idx = train_test_split(bx_df.index, train_size = 0.8, random_state = 2025)\n",
    "bx_train = bx_df.loc[bx_train_idx].copy()\n",
    "bx_test  = bx_df.loc[bx_test_idx].copy()\n",
    "\n",
    "# Getting Lat/Lon as NumPy Arrays\n",
    "X_train = bx_train[[\"lat\", \"lon\"]].values\n",
    "X_test  = bx_test[[\"lat\", \"lon\"]].values\n",
    "\n",
    "# Scaling Lat/Lon coordinates\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled  = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6fd5a77b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86\n",
      "10003\n",
      "4.106979360406633\n"
     ]
    }
   ],
   "source": [
    "# Getting unique neighborhoods\n",
    "print(bx_df[\"nbhd\"].nunique()) # 86 unique neighborhoods in The Bronx\n",
    "print(len(bx_df)) # 10003 unique listings in The Bronx\n",
    "print((len(bx_df) / len(listings)) * 100) # 4.11% of listings are in The Bronx\n",
    "\n",
    "bx_cluster_size = 8 # Setting min clusters to twice the percentage of listings in the borough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bdc13a30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\adria\\anaconda3\\envs\\analytics\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\adria\\anaconda3\\envs\\analytics\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Fitting HDBSCAN\n",
    "cluster = hdbscan.HDBSCAN(min_cluster_size = bx_cluster_size, \n",
    "                        metric = \"euclidean\", # Euclidean metric best for The Bronx - too small of a geo for haversine. Not grid-like for manhattan.\n",
    "                        prediction_data = True, \n",
    "                        cluster_selection_epsilon = 0.05) \n",
    "\n",
    "cluster_labels_train = cluster.fit_predict(X_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ced3a9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigning cluster labels to training data\n",
    "bx_train[\"cluster\"] = cluster_labels_train\n",
    "\n",
    "# Assigning cluster labels to test data with approximate predictions\n",
    "cluster_labels_test, _ = hdbscan.approximate_predict(cluster, X_test_scaled)\n",
    "bx_test[\"cluster\"] = cluster_labels_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f184f95e",
   "metadata": {},
   "source": [
    "## Staten Island Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "afbcd87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subsetting to only Staten Island\n",
    "st_df = listings[listings[\"boro\"] == \"Staten Island\"].copy()\n",
    "\n",
    "# Train-Test Splits by index\n",
    "st_train_idx, st_test_idx = train_test_split(st_df.index, train_size = 0.8, random_state = 2025)\n",
    "st_train = st_df.loc[st_train_idx].copy()\n",
    "st_test  = st_df.loc[st_test_idx].copy()\n",
    "\n",
    "# Getting Lat/Lon as NumPy Arrays\n",
    "X_train = st_train[['lat', 'lon']].values\n",
    "X_test  = st_test[['lat', 'lon']].values\n",
    "\n",
    "# Scaling Lat/Lon coordinates\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled  = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e19192e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52\n",
      "3495\n",
      "1.4349587988224717\n"
     ]
    }
   ],
   "source": [
    "# Getting unique neighborhoods\n",
    "print(st_df[\"nbhd\"].nunique()) # 52 unique neighborhoods in Staten Island\n",
    "print(len(st_df)) # 3495 unique listings in Staten Island\n",
    "print((len(st_df) / len(listings)) * 100) # Only 1.44% of listings are in Staten Island\n",
    "\n",
    "st_cluster_size = 4 # Very few cluster sizes based on the custom formula (none), so setting it to 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1fd1741f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\adria\\anaconda3\\envs\\analytics\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\adria\\anaconda3\\envs\\analytics\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Fitting HDBSCAN\n",
    "cluster = hdbscan.HDBSCAN(min_cluster_size = bx_cluster_size, \n",
    "                        metric = \"euclidean\",  # Euclidean metric best for staten island\n",
    "                        prediction_data = True,\n",
    "                        cluster_selection_epsilon = 0.05)\n",
    "\n",
    "cluster_labels_train = cluster.fit_predict(X_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "78e5b3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigning cluster labels to training data\n",
    "st_train[\"cluster\"] = cluster_labels_train\n",
    "\n",
    "# Assigning cluster labels to test data with approximate predictions\n",
    "cluster_labels_test, _ = hdbscan.approximate_predict(cluster, X_test_scaled)\n",
    "st_test[\"cluster\"] = cluster_labels_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237952ab",
   "metadata": {},
   "source": [
    "## Manhattan Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "061825c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subsetting to only Manhattan\n",
    "mtn_df = listings[listings[\"boro\"] == \"Manhattan\"]\n",
    "\n",
    "# Train-Test Splits by index\n",
    "mtn_train_idx, mtn_test_idx = train_test_split(mtn_df.index, train_size = 0.8, random_state = 2025)\n",
    "mtn_train = mtn_df.loc[mtn_train_idx]\n",
    "mtn_test  = mtn_df.loc[mtn_test_idx]\n",
    "\n",
    "# Getting Lat/Lon as NumPy Arrays\n",
    "X_train = mtn_train[['lat', 'lon']].values\n",
    "X_test  = mtn_test[['lat', 'lon']].values\n",
    "\n",
    "# Scaling Lat/Lon coordinates\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled  = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ba08dc0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "333\n",
      "107497\n",
      "44.135555363954\n"
     ]
    }
   ],
   "source": [
    "# Getting unique neighborhoods\n",
    "print(mtn_df[\"nbhd\"].nunique()) #  unique neighborhoods in Manhattan\n",
    "print(len(mtn_df)) # 107497 unique listings in Manhattan\n",
    "print((len(mtn_df) / len(listings)) * 100) # 44.14% of listings are in Manhattan\n",
    "\n",
    "mtn_cluster_size = 44 # Setting number of clusters to percentage of listings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "978f0ea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\adria\\anaconda3\\envs\\analytics\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\adria\\anaconda3\\envs\\analytics\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Fitting HDBSCAN\n",
    "cluster = hdbscan.HDBSCAN(min_cluster_size = mtn_cluster_size, \n",
    "                        metric = \"euclidean\", # The Manhattan metric is best for the grid-like pattern that Manhattan has\n",
    "                        prediction_data = True, \n",
    "                        cluster_selection_epsilon = 0.05) \n",
    "\n",
    "cluster_labels_train = cluster.fit_predict(X_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "084f21af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigning cluster labels to training data\n",
    "mtn_train[\"cluster\"] = cluster_labels_train\n",
    "\n",
    "# Assigning cluster labels to test data with approximate predictions\n",
    "cluster_labels_test, _ = hdbscan.approximate_predict(cluster, X_test_scaled)\n",
    "mtn_test[\"cluster\"] = cluster_labels_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264e55b8",
   "metadata": {},
   "source": [
    "## Concatenating Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d2eb7166",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making a function to label clusters in each borough\n",
    "def add_prefix(df, boro_code):\n",
    "    df[\"cluster\"] = df[\"cluster\"].astype(str)\n",
    "    df.loc[df[\"cluster\"] != \"-1\", \"cluster\"] = boro_code + \"_\" + df[\"cluster\"]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "46da6811",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding prefixes to each borough and concatenating trained clusters and approximated clusters\n",
    "qns_final = add_prefix(pd.concat([qns_train, qns_test]), \"qns\")\n",
    "bk_final  = add_prefix(pd.concat([bk_train, bk_test]), \"bk\")\n",
    "bx_final  = add_prefix(pd.concat([bx_train, bx_test]), \"bx\")\n",
    "st_final  = add_prefix(pd.concat([st_train, st_test]), \"st\")\n",
    "mtn_final = add_prefix(pd.concat([mtn_train, mtn_test]), \"mtn\")\n",
    "\n",
    "# Making a final lat/lon df\n",
    "final = pd.concat([qns_final, bk_final, bx_final, st_final, mtn_final])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ce6b5927",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accomm</th>\n",
       "      <th>avail_30</th>\n",
       "      <th>avail_365</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>beds</th>\n",
       "      <th>calculated_host_listings_count</th>\n",
       "      <th>calculated_host_listings_count_entire_homes</th>\n",
       "      <th>calculated_host_listings_count_private_rooms</th>\n",
       "      <th>calculated_host_listings_count_shared_rooms</th>\n",
       "      <th>...</th>\n",
       "      <th>aug</th>\n",
       "      <th>prop_apt</th>\n",
       "      <th>prop_hotel</th>\n",
       "      <th>prop_other</th>\n",
       "      <th>prop_vacation_home</th>\n",
       "      <th>prop_entire_home_apt</th>\n",
       "      <th>prop_hotel_room</th>\n",
       "      <th>prop_private_room</th>\n",
       "      <th>prop_shared_room</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>121864</th>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>89</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>qns_14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189604</th>\n",
       "      <td>5</td>\n",
       "      <td>29</td>\n",
       "      <td>364</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>qns_88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118835</th>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>138</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>qns_57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104204</th>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>225</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>qns_88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214543</th>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>139</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>qns_88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195516</th>\n",
       "      <td>6</td>\n",
       "      <td>29</td>\n",
       "      <td>364</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>mtn_275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84440</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>244</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54833</th>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>89</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103334</th>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>89</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>25</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154385</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>320</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>243561 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        accomm  avail_30  avail_365  bathrooms  bedrooms  beds  \\\n",
       "121864       2        29         89        1.0       1.0   2.0   \n",
       "189604       5        29        364        1.0       3.0   3.0   \n",
       "118835       2        17        138        1.0       1.0   1.0   \n",
       "104204       4        12        225        1.0       2.0   2.0   \n",
       "214543       1        20        139        1.0       1.0   1.0   \n",
       "...        ...       ...        ...        ...       ...   ...   \n",
       "195516       6        29        364        1.0       2.0   3.0   \n",
       "84440        3         9        244        1.0       1.0   1.0   \n",
       "54833        2        30         89        1.0       1.0   1.0   \n",
       "103334       2        30         89        1.0       4.0   4.0   \n",
       "154385       2         0        320        1.0       1.0   1.0   \n",
       "\n",
       "        calculated_host_listings_count  \\\n",
       "121864                               1   \n",
       "189604                               1   \n",
       "118835                               1   \n",
       "104204                               1   \n",
       "214543                               1   \n",
       "...                                ...   \n",
       "195516                               6   \n",
       "84440                                1   \n",
       "54833                                1   \n",
       "103334                              25   \n",
       "154385                               7   \n",
       "\n",
       "        calculated_host_listings_count_entire_homes  \\\n",
       "121864                                            0   \n",
       "189604                                            0   \n",
       "118835                                            0   \n",
       "104204                                            1   \n",
       "214543                                            0   \n",
       "...                                             ...   \n",
       "195516                                            6   \n",
       "84440                                             1   \n",
       "54833                                             0   \n",
       "103334                                           24   \n",
       "154385                                            0   \n",
       "\n",
       "        calculated_host_listings_count_private_rooms  \\\n",
       "121864                                             1   \n",
       "189604                                             1   \n",
       "118835                                             1   \n",
       "104204                                             0   \n",
       "214543                                             1   \n",
       "...                                              ...   \n",
       "195516                                             0   \n",
       "84440                                              0   \n",
       "54833                                              1   \n",
       "103334                                             1   \n",
       "154385                                             3   \n",
       "\n",
       "        calculated_host_listings_count_shared_rooms  ...  aug  prop_apt  \\\n",
       "121864                                            0  ...    0         1   \n",
       "189604                                            0  ...    0         1   \n",
       "118835                                            0  ...    0         1   \n",
       "104204                                            0  ...    0         1   \n",
       "214543                                            0  ...    0         1   \n",
       "...                                             ...  ...  ...       ...   \n",
       "195516                                            0  ...    0         1   \n",
       "84440                                             0  ...    0         1   \n",
       "54833                                             0  ...    0         1   \n",
       "103334                                            0  ...    0         1   \n",
       "154385                                            4  ...    0         1   \n",
       "\n",
       "        prop_hotel  prop_other  prop_vacation_home  prop_entire_home_apt  \\\n",
       "121864           0           0                   0                     0   \n",
       "189604           0           0                   0                     0   \n",
       "118835           0           0                   0                     0   \n",
       "104204           0           0                   0                     1   \n",
       "214543           0           0                   0                     0   \n",
       "...            ...         ...                 ...                   ...   \n",
       "195516           0           0                   0                     1   \n",
       "84440            0           0                   0                     1   \n",
       "54833            0           0                   0                     0   \n",
       "103334           0           0                   0                     0   \n",
       "154385           0           0                   0                     0   \n",
       "\n",
       "       prop_hotel_room  prop_private_room prop_shared_room  cluster  \n",
       "121864               0                  1                0   qns_14  \n",
       "189604               0                  1                0   qns_88  \n",
       "118835               0                  1                0   qns_57  \n",
       "104204               0                  0                0   qns_88  \n",
       "214543               0                  1                0   qns_88  \n",
       "...                ...                ...              ...      ...  \n",
       "195516               0                  0                0  mtn_275  \n",
       "84440                0                  0                0       -1  \n",
       "54833                0                  1                0       -1  \n",
       "103334               0                  1                0       -1  \n",
       "154385               0                  1                0       -1  \n",
       "\n",
       "[243561 rows x 60 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Viewing final df of clustered features\n",
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2425745e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34656"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Viewing amount of \"noise\" decided by HDBSCAN\n",
    "final[final[\"cluster\"] == \"-1\"].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "986bbbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing to CSV\n",
    "final.to_csv(\"clustered_listings.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "analytics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
